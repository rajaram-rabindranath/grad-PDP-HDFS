SLURM Enviroment Variables:
Job ID = 3094160
Job Name = HD_BSORT
Job Node List = d07n10s01,d07n18s01
Number of Nodes = 2
Tasks per Nodes = 1
CPUs per task = 
/scratch/jobid = /scratch/3094160
submit Host = k07n14
Subimt Directory = /ifs/user/rajaramr/4/hbsort

MY_HADOOP_HOME=/util/myhadoop/myHadoop-0.2a_hadoop-1.1.1
HADOOP_HOME=/util/hadoop/hadoop-1.1.1
MyHadoop config directory=/ifs/user/rajaramr/4/hbsort/config
Set up the configurations for myHadoop
Number of nodes in nodelist=2
Number of Hadoop nodes requested: 2
Generation Hadoop configuration in directory: /ifs/user/rajaramr/4/hbsort/config
Not persisting HDFS state
Received 2 nodes from PBS
Master is: d07n10s01
Configuring node: d07n10s01
rm -rf /scratch/hadoop-rajaramr/log; mkdir -p /scratch/hadoop-rajaramr/log
rm -rf /scratch/hadoop-rajaramr/data; mkdir -p /scratch/hadoop-rajaramr/data
Configuring node: d07n18s01
rm -rf /scratch/hadoop-rajaramr/log; mkdir -p /scratch/hadoop-rajaramr/log
rm -rf /scratch/hadoop-rajaramr/data; mkdir -p /scratch/hadoop-rajaramr/data
Format HDFS
start dfs
starting namenode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-namenode-d07n10s01.out
d07n18s01: starting datanode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n18s01-datanode-d07n18s01.out
d07n10s01: starting datanode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-datanode-d07n10s01.out
d07n10s01: starting secondarynamenode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-secondarynamenode-d07n10s01.out
start jobtracker (mapred)
starting jobtracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-jobtracker-d07n10s01.out
d07n18s01: starting tasktracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n18s01-tasktracker-d07n18s01.out
d07n10s01: starting tasktracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-tasktracker-d07n10s01.out
copy file to dfs
ls files in dfs
Found 1 items
-rw-r--r--   1 rajaramr supergroup     978453 2014-12-06 19:27 /user/rajaramr/100K
run computation
Num reducers2
Problem size 100000
in_file 100K
out_file result_100K
path =/user/rajaramr/


 JOB WAs SUCCESSFUL


100001 ::time taken ::40437.960044 ms
100000 ::estimated milli 40438 ms
=================== TIME TAKEN ====================
Task name ::attempt_201412061926_0001_m_000002_0 took 2077 ms
Task name ::attempt_201412061926_0001_r_000001_0 took 0 ms
Task name ::attempt_201412061926_0001_r_000000_0 took 10979 ms
Task name ::attempt_201412061926_0001_r_000001_1 took 10696 ms
Task name ::attempt_201412061926_0001_m_000001_0 took 2367 ms
ls files in dfs
copy files in dfs
stop jobtracker (mapred)
stopping jobtracker
d07n10s01: stopping tasktracker
d07n18s01: stopping tasktracker
stop dfs
stopping namenode
d07n10s01: stopping datanode
d07n18s01: stopping datanode
d07n10s01: stopping secondarynamenode
Clean up
Number of Hadoop nodes specified by user: 2
Received 2 nodes from PBS
Clean up node: d07n10s01
rm -rf /scratch/hadoop-rajaramr/data /scratch/hadoop-rajaramr/log
Clean up node: d07n18s01
rm -rf /scratch/hadoop-rajaramr/data /scratch/hadoop-rajaramr/log

