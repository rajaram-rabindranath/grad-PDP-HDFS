SLURM Enviroment Variables:
Job ID = 3094733
Job Name = HD_BSORT
Job Node List = d07n07s02,d07n09s02,d07n10s01,d07n18s01
Number of Nodes = 4
Tasks per Nodes = 1
CPUs per task = 
/scratch/jobid = /scratch/3094733
submit Host = k07n14
Subimt Directory = /ifs/user/rajaramr/4/hbsort

MY_HADOOP_HOME=/util/myhadoop/myHadoop-0.2a_hadoop-1.1.1
HADOOP_HOME=/util/hadoop/hadoop-1.1.1
MyHadoop config directory=/ifs/user/rajaramr/4/hbsort/config
Set up the configurations for myHadoop
Number of nodes in nodelist=4
Number of Hadoop nodes requested: 4
Generation Hadoop configuration in directory: /ifs/user/rajaramr/4/hbsort/config
Not persisting HDFS state
Received 4 nodes from PBS
Master is: d07n07s02
Configuring node: d07n07s02
rm -rf /scratch/hadoop-rajaramr/log; mkdir -p /scratch/hadoop-rajaramr/log
rm -rf /scratch/hadoop-rajaramr/data; mkdir -p /scratch/hadoop-rajaramr/data
Configuring node: d07n09s02
rm -rf /scratch/hadoop-rajaramr/log; mkdir -p /scratch/hadoop-rajaramr/log
rm -rf /scratch/hadoop-rajaramr/data; mkdir -p /scratch/hadoop-rajaramr/data
Configuring node: d07n10s01
rm -rf /scratch/hadoop-rajaramr/log; mkdir -p /scratch/hadoop-rajaramr/log
rm -rf /scratch/hadoop-rajaramr/data; mkdir -p /scratch/hadoop-rajaramr/data
Configuring node: d07n18s01
rm -rf /scratch/hadoop-rajaramr/log; mkdir -p /scratch/hadoop-rajaramr/log
rm -rf /scratch/hadoop-rajaramr/data; mkdir -p /scratch/hadoop-rajaramr/data
Format HDFS
start dfs
starting namenode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n07s02-namenode-d07n07s02.out
d07n10s01: starting datanode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-datanode-d07n10s01.out
d07n18s01: starting datanode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n18s01-datanode-d07n18s01.out
d07n09s02: starting datanode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n09s02-datanode-d07n09s02.out
d07n07s02: starting datanode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n07s02-datanode-d07n07s02.out
d07n07s02: starting secondarynamenode, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n07s02-secondarynamenode-d07n07s02.out
start jobtracker (mapred)
starting jobtracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n07s02-jobtracker-d07n07s02.out
d07n09s02: starting tasktracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n09s02-tasktracker-d07n09s02.out
d07n18s01: starting tasktracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n18s01-tasktracker-d07n18s01.out
d07n10s01: starting tasktracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n10s01-tasktracker-d07n10s01.out
d07n07s02: starting tasktracker, logging to /scratch/hadoop-rajaramr/log/hadoop-rajaramr_d07n07s02-tasktracker-d07n07s02.out
copy file to dfs
ls files in dfs
Found 1 items
-rw-r--r--   1 rajaramr supergroup   10100000 2014-12-06 23:03 /user/rajaramr/1MILL
run computation
Num reducers4
Problem size 1000000
in_file 1MILL
out_file result_1MILL
path =/user/rajaramr/


 JOB WAs SUCCESSFUL


1000001 ::time taken ::95459.558757 ms
1000000 ::estimated milli 95459 ms
=================== TIME TAKEN ====================
Task name ::attempt_201412062302_0001_m_000002_0 took 2525 ms
Task name ::attempt_201412062302_0001_r_000002_0 took 26289 ms
Task name ::attempt_201412062302_0001_r_000001_0 took 26359 ms
Task name ::attempt_201412062302_0001_r_000003_0 took 26933 ms
Task name ::attempt_201412062302_0001_r_000003_1 took 0 ms
Task name ::attempt_201412062302_0001_r_000000_0 took 46483 ms
Task name ::attempt_201412062302_0001_r_000000_1 took 0 ms
Task name ::attempt_201412062302_0001_m_000001_0 took 0 ms
Task name ::attempt_201412062302_0001_r_000004_0 took 1860 ms
ls files in dfs
copy files in dfs
stop jobtracker (mapred)
stopping jobtracker
d07n18s01: stopping tasktracker
d07n10s01: stopping tasktracker
d07n09s02: stopping tasktracker
d07n07s02: stopping tasktracker
stop dfs
stopping namenode
d07n18s01: stopping datanode
d07n10s01: stopping datanode
d07n09s02: stopping datanode
d07n07s02: stopping datanode
d07n07s02: stopping secondarynamenode
Clean up
Number of Hadoop nodes specified by user: 4
Received 4 nodes from PBS
Clean up node: d07n07s02
rm -rf /scratch/hadoop-rajaramr/data /scratch/hadoop-rajaramr/log
Clean up node: d07n09s02
rm -rf /scratch/hadoop-rajaramr/data /scratch/hadoop-rajaramr/log
Clean up node: d07n10s01
rm -rf /scratch/hadoop-rajaramr/data /scratch/hadoop-rajaramr/log
Clean up node: d07n18s01
rm -rf /scratch/hadoop-rajaramr/data /scratch/hadoop-rajaramr/log

